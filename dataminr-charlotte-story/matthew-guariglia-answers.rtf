{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\froman\fcharset0 Times-Roman;\f2\froman\fcharset0 Times-Bold;
}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red0\green0\blue233;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c0\c0\c93333;}
\margl1440\margr1440\vieww19420\viewh12900\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \
\pard\pardeftab720\sl280\partightenfactor0

\f1\fs48 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Matthew Guariglia responsees:
\fs24 \
\
\pard\pardeftab720\sl280\sa240\partightenfactor0
\cf2 Hello Patrick, \
\uc0\u8232 I\'92m sorry that today I don\'92t have time to answer all your questions, but here are my most essential thoughts:\
\pard\pardeftab720\sl280\sa240\partightenfactor0

\f2\b \cf2 \'a0
\f1\b0 \

\f2\b -- I am writing about Dataminr, a company that, among other things, has helped police in the past to keep an eye on protests by looking at the contents of protesters' publicly available social media feeds. Are you surprised that Charlotte's police department has a contract with this company? How do you feel about it?
\f1\b0 \

\f2\b \'a0
\f1\b0 \
I am not surprised. Police departments currently operate with a \'93collect it all\'94 kind of mentality, and especially after the protests against police violence this summer, it is no surprise that they would invest in more surveillance technology. Surveillance of public social media, like surveillance of people at a public protest, may seem common sense\'97but the more prolific it becomes the more of a danger it poses to First Amendment-protected freedoms. People are far less likely to go out and protest and participate politically if they think their tweets and actions in public are being closely monitored by the exact institutions they seek to change, namely police departments. History shows us that protesting again police violence or for police reform comes at a high risk of retribution or reprisals, which is heightened when activists and casual protestors are being surveilled. \'a0\

\f2\b \'a0
\f1\b0 \

\f2\b -- The FBI recently arrested a BLM protester, claiming that his tweets showed he was "on a path to radicalization." (See {\field{\*\fldinst{HYPERLINK "https://www.washingtonpost.com/nation/2021/02/14/fbi-arrest-left-wing-violence/"}}{\fldrslt \cf3 \ul \ulc3 \strokec3 https://www.washingtonpost.com/nation/2021/02/14/fbi-arrest-left-wing-violence/}}) Is that a valid reason to arrest someone? If not, how does this arrest set a precedent for future actions?
\f1\b0 \
\'a0\
One of the key problems in the U.S. that many people in government, civil society, and the media have pointed out is the asymmetry of surveillance and policing in American political life. Monitoring specific, credible, and violent threats is one thing\'97but what sets a dangerous precedent and what undermines public trust in institutions that are supposedly given these powers to protect all people, is when those enforcement powers appear to be used along political and partisan lines. \'93Being on a path\'94 and \'93radicalization\'94 are both subjective terms that are given more credence if the people sitting behind the computer choose to believe that some political principals are more violent than others\'97this is easily skewed by the politics within police departments and re-iterates the threat of reprisal and retribution surveillance creates when used against activists seeking to change policing in the U.S. \'a0\'a0\
\'a0\
\'a0\

\f2\b -- Have you ever posted anything online that you wouldn't want the police to see?
\f1\b0 \

\f2\b \'a0
\f1\b0 \
Technologies like Dataminr and social media surveillance certainly introduce some fear of retribution for people working in civil liberties nonprofits, activists, or other interested parties like journalists and academics who tweet about issues of race and criminal justice. \'a0\

\f2\b \'a0
\f1\b0 \

\f2\b \'a0
\f1\b0 \

\f2\b -- Is there a risk of activists self-censoring online? If so, what effects could this have on the society in which they operate?
\f1\b0 \

\f2\b \'a0
\f1\b0 \
There is absolutely a fear that as social media surveillance becomes more prevalent, people will self-censor online. This can have a terrible impact on, not just the freedom to protest, but also the right to open political debate unburdened by fear of government reprisal. \

\f2\b \'a0
\f1\b0 \

\f2\b -- The Intercept recently reported that while Dataminr touts its artificial intelligence algorithms, many of its results are powered by human analysts who "brought their prejudices and preconceptions along with their expertise, and were pressed to search specific neighborhoods, streets, and even housing complexes for crime, sources said." (See {\field{\*\fldinst{HYPERLINK "https://theintercept.com/2020/10/21/dataminr-twitter-surveillance-racial-profiling/"}}{\fldrslt \cf3 \ul \ulc3 \strokec3 https://theintercept.com/2020/10/21/dataminr-twitter-surveillance-racial-profiling/}}) Does that surprise you? Why or why not?
\f1\b0 \

\f2\b \'a0
\f1\b0 \
This is a key issue with social media surveillance. Police or private surveillance contractors are peering into a conversation already in progress with its own linguistic, cultural, regional, and familiar specificities. Misunderstandings can, and historically have, had catastrophic consequences when police can base investigations, arrests, harassment, and more surveillance on what they see on social media while monitoring people through a lens of racist stereotype or pre-conceived notions. \'a0\

\f2\b \'a0
\f1\b0 \

\f2\b \'a0
\f1\b0 \

\f2\b -- While reporting in The Intercept casts doubt on the idea that Dataminr's information is algorithmically generated, the company still claims that algorithms generate the majority of their alerts. If that's true -- a big if, but one we'll indulge nonetheless -- does that solve the problem of bias?
\f1\b0 \

\f2\b \'a0
\f1\b0 \

\f2\b \'a0
\f1\b0 \
Algorithms are generated by human beings and create a system of surveillance and data analysis that have the same biases as the humans that designed it\'97it just happened to be automated. An automated system of evaluating threats, like having people who don\'92t understand the culture or context of the people they are surveilling, is likely to make the same mistakes. \
}